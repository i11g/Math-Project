get_ipython().run_line_magic("matplotlib", " inline")


import numpy as np
import pandas as pd
import random
import time
import os
from IPython.display import display
import matplotlib.pyplot as plt


























def solve_knapsack_dp(weights, values, capacity):
    n = len(weights)
    dp = np.zeros((n + 1, capacity+1), dtype=int)
    for i in range(1, n + 1):
        w_i, v_i = weights[i - 1], values[i - 1]
        for w in range(capacity + 1):
            if w_i <= w:
                dp[i, w] = max(v_i + dp[i-1, w-w_i], dp[i-1, w])
            else:
                dp[i, w] = dp[i-1, w] 

    selected = np.zeros(n, dtype=bool)
    w = capacity
    for i in range(n, 0, -1):
        if dp[i, w] != dp[i - 1, w]:
            selected[i - 1] = True
            w -= weights[i - 1]
    return dp[n, capacity], selected


weights = [2, 3, 4]
values = [5, 7, 8]
capacity = 6
max_value = solve_knapsack_dp(weights, values, capacity)
print(f"For weigths = {weights}, values ={values}, capacity = {capacity} , max_value ={max_value}")





def solve_knapsack_ga(weights, values, capacity,
                               population_size=100,
                               num_generations=500,
                               mutation_rate=0.01,
                               tournament_size=5,
                               elitism=True,
                               penalty_coef=1.0):
    n = len(weights)

    def fitness(ind):
        w = (weights * ind).sum()
        v = (values  * ind).sum()
        if w <= capacity:
            return v
        else:
            # Penalize overweight
            return v - penalty_coef * (w - capacity)
    def create():
        return np.random.randint(0, 2, size=n)
    
    def tour(pop, fits):
        competitors = random.sample(range(len(pop)), tournament_size)
        return pop[max(competitors, key=lambda i:fits[i])].copy()
    
    def crossover(p1, p2):
        pt = random.randint(1, n-1)
        return np.concatenate([p1[:pt], p2[pt:]]), np.concatenate([p2[:pt], p1[pt:]])
    
    def mutate(ind):
        for i in range(n):
            if random.random() < mutation_rate:
                ind[i] ^= 1
        return ind
        
    pop = [create() for _ in range(population_size)]
    best_val, best_ind = 0, pop[0].copy()
    
    for _ in range(num_generations):
        fits = [fitness(ind) for ind in pop]
        idx = int(np.argmax(fits))
        if fits[idx] > best_val:
            best_val, best_ind = fits[idx], pop[idx].copy()
            new_pop = []
        if elitism:
            new_pop.append(best_ind.copy())
        while len(new_pop) < population_size:
            p1, p2 = tour(pop, fits), tour(pop, fits)
            c1, c2 = crossover(p1, p2)
            new_pop.extend([mutate(c1), mutate(c2)])
        pop = new_pop[:population_size]
    return best_val, best_ind





def generate_knapsack_instance(n, weight_range=(1,100), value_range=(1,100), capacity_factor=0.5):
    weights = np.random.randint(weight_range[0], weight_range[1]+1, size=n)
    values  = np.random.randint(value_range[0], value_range[1]+1, size=n)
    capacity = int(weights.sum() * capacity_factor)
    return weights, values, capacity

def run_dp(weights, values, capacity):
    t0 = time.perf_counter()
    value, selected = solve_knapsack_dp(weights, values, capacity)
    return value, selected, time.perf_counter() - t0

def run_ga(weights, values, capacity, params):
    t0 = time.perf_counter()
    value, selected = solve_knapsack_ga(
        weights, values, capacity,
        population_size=params['population_size'],
        num_generations=params['num_generations'],
        mutation_rate=params['mutation_rate'],
        tournament_size=params['tournament_size'],
        elitism=params['elitism']   
    )
    return value, selected, time.perf_counter() - t0

# Benchmark function with quality measure
def benchmark_with_quality(ns, repeats=5, ga_params=None):
    # always start with an empty results list
    results = []

    if ga_params is None:
        ga_params = {
            'population_size': 100,
            'num_generations': 500,
            'mutation_rate': 0.01,
            'tournament_size': 5,
            'elitism': True 
        }

    for n in ns:
        dp_times, ga_times = [], []
        dp_vals,  ga_vals  = [], []
        for _ in range(repeats):
            w, v, C = generate_knapsack_instance(n)
            val_dp, _, t_dp = run_dp(w, v, C)
            val_ga, _, t_ga = run_ga(w, v, C, ga_params)
            dp_times.append(t_dp)
            ga_times.append(t_ga)
            dp_vals.append(val_dp)
            ga_vals.append(val_ga)

        mean_dp_val = np.mean(dp_vals)
        mean_ga_val = np.mean(ga_vals)
        results.append({
            'n_items': n,
            'dp_time_mean': np.mean(dp_times),
            'ga_time_mean': np.mean(ga_times),
            'dp_value_mean': mean_dp_val,
            'ga_value_mean': mean_ga_val,
            'quality_ratio': mean_ga_val / mean_dp_val
        })
    return pd.DataFrame(results)

# Define and run
ns = [10, 15, 20, 30, 50, 80, 100, 200, 300, 400, 500]
ga_params = {
    'population_size': 200,
    'num_generations': 500,
    'mutation_rate': 0.01,
    'tournament_size': 5,
    'elitism': True}
df_quality = benchmark_with_quality(ns, repeats=5, ga_params=ga_params)

# Display results
display(df_quality)





# Plot runtime comparison of DP vs GA vs number of items       
plt.figure(figsize=(8, 6))
plt.plot(df_quality['n_items'], df_quality['dp_time_mean'], marker='o', label='DP Time')
plt.plot(df_quality['n_items'], df_quality['ga_time_mean'], marker='s', label='GA Time')
plt.xlabel('Number of Items')
plt.ylabel('Mean Runtime (s)')
plt.title('Runtime Comparison: DP vs GA')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig('runtime_comparison.png')
plt.show()
 
# Plot quality ratio vs number of items
plt.figure(figsize=(8, 6))
plt.plot(df_quality['n_items'], df_quality['quality_ratio'], marker='o')
plt.xlabel('Number of Items')
plt.ylabel('GA / DP Quality Ratio')
plt.title('Solution Quality Ratio vs Problem Size')
plt.grid(True)
plt.tight_layout()
plt.savefig("solution_quality.png")
plt.show()











def generate_knapsack_instance(n, weight_range=(1,100), value_range=(1,100), capacity_factor=0.5):
    weights = np.random.randint(weight_range[0], weight_range[1]+1, size=n)
    values  = np.random.randint(value_range[0], value_range[1]+1, size=n)
    capacity = int(weights.sum() * capacity_factor)
    return weights, values, capacity

def run_dp(weights, values, capacity):
    t0 = time.perf_counter()
    value, selected = solve_knapsack_dp(weights, values, capacity)
    return value, selected, time.perf_counter() - t0

def run_ga(weights, values, capacity, params):
    t0 = time.perf_counter()
    value, selected = solve_knapsack_ga(
        weights, values, capacity,
        population_size=params['population_size'],
        num_generations=params['num_generations'],
        mutation_rate=params['mutation_rate'],
        tournament_size=params['tournament_size'],
        elitism=params['elitism']
    )
    return value, selected, time.perf_counter() - t0

def benchmark_varying_capacity(ns, capacity_factors, repeats=3, ga_params=None):
    if ga_params is None: ga_params = {
            'population_size': 200,
            'num_generations': 500,
            'mutation_rate': 0.01,
            'tournament_size': 5,
            'elitism': True }  
    records = []
    for n in ns:
        for cf in capacity_factors:
            dp_times, ga_times = [], []
            dp_vals, ga_vals = [], []
            for _ in range(repeats):
                w, v, C = generate_knapsack_instance(n, capacity_factor=cf)
                val_dp, _, t_dp = run_dp(w, v, C)
                val_ga, _, t_ga = run_ga(w, v, C, ga_params)
                dp_times.append(t_dp); dp_vals.append(val_dp)
                ga_times.append(t_ga); ga_vals.append(val_ga)
            records.append({
                'n_items': n,
                'capacity_factor': cf,
                'dp_time_mean': np.mean(dp_times),
                'ga_time_mean': np.mean(ga_times),
                'dp_value_mean': np.mean(dp_vals),
                'ga_value_mean': np.mean(ga_vals),
                'quality_ratio': np.mean(ga_vals) / np.mean(dp_vals)
            })
    return pd.DataFrame(records)

# Example usage:
ns = [200]
cfs = [0.25, 0.5, 0.75]
df_cap = benchmark_varying_capacity(ns, cfs, repeats=3, ga_params=ga_params)
display(df_cap)





def plot_time_vs_capacity(df):
    """
    Plots mean runtime of DP and GA against capacity factor for each n_items,
    ensuring data are sorted so lines render correctly.
    """
    # Ensure proper ordering
    df_sorted = df.sort_values(['n_items', 'capacity_factor'])
    
    plt.figure(figsize=(12, 6))
    for n, group in df_sorted.groupby('n_items'):
        x = group['capacity_factor']
        y_dp = group['dp_time_mean']
        y_ga = group['ga_time_mean']
        plt.plot(x, y_dp, marker='o', label=f'DP n={n}')
        plt.plot(x, y_ga, marker='x', linestyle='--', label=f'GA n={n}')
    
    plt.xlabel('Capacity Factor')
    plt.ylabel('Mean Time (seconds)')
    plt.title('DP vs GA Runtime vs Capacity Factor')
    plt.legend(title='Algorithm / n_items')
    plt.grid(True)
    plt.savefig("runtime_comparision_capacity.png")
    plt.tight_layout()
    plt.show()


plot_time_vs_capacity(df_cap)








# Optimized GA Parameter Sensitivity Experiment
def run_ga_sensitivity(n_items=300, repeats=5):
    default_ga_params = {
        'population_size': 100,
        'num_generations': 200,
        'mutation_rate': 0.01,
        'tournament_size': 3,
        'elitism': True
    }
    sweeps = {
        'population_size': [50, 100, 200, 500],
        'mutation_rate': [0.001, 0.01, 0.05, 0.1],
        'num_generations': [50, 100, 200, 500]
    }

    raw_results = []
    for _ in range(repeats):
        w, v, C = generate_knapsack_instance(n_items)
        dp_val, _, _ = run_dp(w, v, C)  # one DP run per instance

        for param, values in sweeps.items():
            for val in values:
                ga_params = default_ga_params.copy()
                ga_params[param] = val
                val_ga, _, t_ga = run_ga(w, v, C, ga_params)
                raw_results.append({
                    'parameter': param,
                    'value': val,
                    'dp_value': dp_val,
                    'ga_value': val_ga,
                    'ga_time': t_ga
                })

                df_raw = pd.DataFrame(raw_results)

    # Aggregate means
    df_agg = df_raw.groupby(['parameter','value']).agg(
        dp_value_mean=('dp_value','mean'),
        ga_value_mean=('ga_value','mean'),
        ga_time_mean=('ga_time','mean')
    ).reset_index()
    df_agg['quality_ratio'] = df_agg['ga_value_mean'] / df_agg['dp_value_mean']
    
    df_sense=('GAParameterSensitivity', df_agg)
    display(df_sense)
    return df_agg

# Run the optimized sensitivity experiment
df_sensitivity = run_ga_sensitivity(n_items=300, repeats=5)





# df_sensitivity: DataFrame with columns
#   ['parameter', 'value', 'ga_time_mean', 'quality_ratio']

parameters = ['population_size', 'mutation_rate', 'num_generations']

for param in parameters:
    # Filter for this parameter
    df_p = df_sensitivity[df_sensitivity['parameter'] == param]
    
    # Create a figure with a single axes
    fig, ax1 = plt.subplots()
    
    # Plot GA runtime
    ax1.plot(df_p['value'], df_p['ga_time_mean'], label='Runtime')
    ax1.set_xlabel(param.replace('_', ' ').title())
    ax1.set_ylabel('GA Runtime (s)')
    
    # Create a twinned axis for quality ratio
    ax2 = ax1.twinx()
    ax2.plot(df_p['value'], df_p['quality_ratio'], label='Quality Ratio')
    ax2.set_ylabel('Solution Quality Ratio')
    
    # Combine legends from both axes
    lines1, labels1 = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')
    
    # Title
    plt.title(f'Sensitivity to {param.replace("_", " ").title()}')
    
    # Render
    plt.show()











def solve_knapsack_ga(weights, values, capacity,
                      population_size=200,
                      num_generations=500,
                      base_mutation_rate=0.05,
                      tournament_size=5,
                      elitism=True,
                      penalty_coef=1.0):
    n = len(weights)

    def fitness(ind):
        w = (weights * ind).sum()
        v = (values * ind).sum()
        if w <= capacity:
            return v
        else:
            return v - penalty_coef * (w - capacity)

    def greedy_init():
        ind = np.zeros(n, dtype=int)
        remaining = capacity
        for i in np.argsort(-values / weights):
            if weights[i] <= remaining:
                ind[i] = 1
                remaining -= weights[i]
        return ind

    def create_random():
        return np.random.randint(0, 2, size=n)

    def tournament(pop, fits):
        aspirants = random.sample(range(len(pop)), tournament_size)
        best = max(aspirants, key=lambda i: fits[i])
        return pop[best].copy()

    def crossover(p1, p2):
        mask = np.random.rand(n) < 0.5
        return np.where(mask, p1, p2), np.where(mask, p2, p1)

    def repair(ind):
        overweight = (weights * ind).sum() - capacity
        if overweight <= 0:
            return ind
        ratios = values / weights
        for i in np.argsort(ratios):
            if ind[i] == 1:
                ind[i] = 0
                overweight -= weights[i]
                if overweight <= 0:
                    break
        return ind

    def mutate(ind, curr_rate):
        for i in range(n):
            if random.random() < curr_rate:
                ind[i] ^= 1
        return ind

    # initialize population: one greedy, rest random
    pop = [greedy_init()] + [create_random() for _ in range(population_size - 1)]
    best_val = -1
    best_ind = None
    history = []

    for gen in range(num_generations):
        fits = [fitness(ind) for ind in pop]
        history.append((max(fits), np.mean(fits)))

        # update global best
        current_best = max(fits)
        if current_best > best_val:
            best_val = current_best
            best_ind = pop[int(np.argmax(fits))].copy()

        # prepare next generation
        new_pop = []
        if elitism:
            new_pop.append(best_ind.copy())

        # linearly decay mutation rate
        curr_mut_rate = base_mutation_rate * (1 - gen / num_generations)

        while len(new_pop) < population_size:
            p1 = tournament(pop, fits)
            p2 = tournament(pop, fits)
            c1, c2 = crossover(p1, p2)
            c1 = repair(mutate(c1, curr_mut_rate))
            c2 = repair(mutate(c2, curr_mut_rate))
            new_pop.extend([c1, c2])

        pop = new_pop[:population_size]

    return best_val, best_ind, history



def generate_knapsack_instance(n, weight_range=(1, 100), value_range=(1, 100), capacity_factor=0.5):
    weights = np.random.randint(weight_range[0], weight_range[1] + 1, size=n)
    values = np.random.randint(value_range[0], value_range[1] + 1, size=n)
    capacity = int(weights.sum() * capacity_factor)
    return weights, values, capacity


def run_dp(weights, values, capacity):
    t0 = time.perf_counter()
    value, selected = solve_knapsack_dp(weights, values, capacity)
    return value, selected, time.perf_counter() - t0


def run_ga(weights, values, capacity, params):
    t0 = time.perf_counter()
    value, selected, _ = solve_knapsack_ga(
        weights, values, capacity,
        population_size=params['population_size'],
        num_generations=params['num_generations'],
        base_mutation_rate=params['mutation_rate'],
        tournament_size=params['tournament_size'],
        elitism=params['elitism'],
        penalty_coef=params.get('penalty_coef', 1.0)
    )
    return value, selected, time.perf_counter() - t0


def benchmark_with_quality(ns, repeats=5, ga_params=None):
    if ga_params is None:
        ga_params = {
            'population_size': 200,
            'num_generations': 500,
            'mutation_rate': 0.01,
            'tournament_size': 5,
            'elitism': True,
            'penalty_coef': 1.0
        }
    results = []
    for n in ns:
        dp_times, ga_times = [], []
        dp_vals, ga_vals = [], []
        for _ in range(repeats):
            w, v, C = generate_knapsack_instance(n)
            val_dp, _, t_dp = run_dp(w, v, C)
            val_ga, _, t_ga = run_ga(w, v, C, ga_params)
            dp_times.append(t_dp)
            ga_times.append(t_ga)
            dp_vals.append(val_dp)
            ga_vals.append(val_ga)
        results.append({
            'n_items': n,
            'dp_time_mean': np.mean(dp_times),
            'ga_time_mean': np.mean(ga_times),
            'dp_value_mean': np.mean(dp_vals),
            'ga_value_mean': np.mean(ga_vals),
            'quality_ratio': np.mean(ga_vals) / np.mean(dp_vals)
        })
    return pd.DataFrame(results)


if __name__ == "__main__":
    ns = [10, 20, 30, 50, 100, 200, 300, 400, 500]
    ga_params = {
        'population_size': 200,
        'num_generations': 500,
        'mutation_rate': 0.01,
        'tournament_size': 5,
        'elitism': True,
        'penalty_coef': 1.0
    }
    df_quality = benchmark_with_quality(ns, repeats=5, ga_params=ga_params)
    print(df_quality)






