{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0369c32e-af83-44a9-979f-ff3112140492",
   "metadata": {},
   "source": [
    " Techniques such as grid search or random search may be employed to systematically explore the parameter space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ab2c56-63de-4aab-addb-5d49e5322490",
   "metadata": {},
   "source": [
    "#### Bellman Recurrence\n",
    "Let $V(x)$ denote the optimal value for state $x$. Suppose that from state $x$ you choose an action $u$ from the set of feasible actions $\\mathcal{U}(x)$, which transitions you to state $ y \\;=\\; f(x,u) $ with immediate cost (or negative reward) $c\\bigl(x,u,f(x,u)\\bigr)$. \n",
    "Then the optimal value satisfies the recurrence\n",
    "$$vV(x)\n",
    "\\;=\\;\n",
    "\\min_{u \\in \\mathcal{U}(x)}\n",
    "\\Bigl\\{\\,\n",
    "  c\\bigl(x,u,f(x,u)\\bigr)\n",
    "  \\;+\\;\n",
    "  V\\bigl(f(x,u)\\bigr)\n",
    "\\Bigr\\}\n",
    "$$\n",
    "or, in a maximization setting,\n",
    "$$ V(x) \\;=\\; \\max_{u \\in \\mathcal{U}(x)} \\Bigl\\{r\\bigl(x,u,f(x,u)\\bigr) \\;+\\; V\\bigl(f(x,u)\\bigr) \\Bigr\\}. $$\n",
    "\n",
    "#### Base Cases\n",
    "To ground the recurrence, one must specify boundary conditions. For example, if $x^*$ is a terminal (or absorbing) state, one typically sets\n",
    "$\n",
    "  V(x^*) \\;=\\; 0\n",
    "  \\quad\\text{(or some known terminal value).}\n",
    "$\n",
    "\n",
    "*#### Putting It All Together*\n",
    "- Identify the state space $\\mathcal{X}$ and action sets $\\mathcal{U}(x)$ for each $x\\in\\mathcal{X}$.\n",
    "- Derive the state transition function $y = f(x,u)$ and cost (or reward) function $c(x,u,y)$ (or $r(x,u,y)$).\n",
    "- Write down the Bellman recurrence \\eqref{eq:bellman}, choosing $\\min$ for cost-minimization or $\\max$ for reward-maximization.\n",
    "- Specify base cases $V(x^*)$ for terminal states.\n",
    "- Choose an implementation style:\n",
    "  - Top–down: Recursively compute $V(x)$ and memoize.\n",
    "  - Bottom–up: Order states, then iteratively fill a table for $V(x)$.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3d51bb-3c19-48dc-99cf-40722c548031",
   "metadata": {},
   "source": [
    "- Fewer stagnated elite solutions. With a very low μ (0.001), the population can get stuck in local peaks for more generations often forcing more comparisons or bookkeeping (e.g. evaluating similar chromosomes over and over).\n",
    "- Higher mutation → faster diversity injection. The algorithm explores more broadly, so it may converge “fast enough” to a decent ensemble and skip some extra crossovers. (In many implementations, if large swaths of the population become identical, you still run the same loops. But if mutation keeps them varied, you avoid extremely similar‐chromosome checks or rebuild steps that can add small overhead.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ebd65d-3e9e-40a7-ba9e-cc02360e6596",
   "metadata": {},
   "source": [
    "The values in the table are computed using the recurrence relation described bellow, progressing from smaller subproblems to the final solution, which is found at $dp[n][W]$.\n",
    "\n",
    "Let $dp[i][w]$ represent the maximum value that can be obtained by considering items up to index $i$ (from 0 to $n-1$) with a knapsack capacity of $w$ (from 0 to $W$). The recurrence relation is defined as follows $1 \\le i \\le n$ and $0 \\le w \\le W$: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd450be2-c7e2-42a6-829a-64defdd62ed7",
   "metadata": {},
   "source": [
    "% Project Summary (Abstract) for 0–1 Knapsack DP Implementation\n",
    "\\section*{Abstract}\n",
    "This project presents a robust implementation and analysis of the classic 0–1 knapsack problem using a dynamic programming (DP) approach, executed and visualized within Jupyter notebooks. We formally define the state\n",
    "$$\n",
    "  \\mathrm{DP}[i][w]=\n",
    "    \\max\\bigl\\{\\text{total value using items }1,\\dots,i\\text{ with capacity }w\\bigr\\},\n",
    "    \\quad0\\le i\\le n,\\;0\\le w\\le W.\n",
    "$$\n",
    "The recurrence\n",
    "\\[\n",
    "  \\mathrm{DP}[i][w]=\n",
    "    \\begin{cases}\n",
    "      \\max\\bigl(\\mathrm{DP}[i-1][w],\\,\\mathrm{DP}[i-1][w-w_i]+v_i\\bigr), & w_i\\le w,\\\\\n",
    "      \\mathrm{DP}[i-1][w], & w_i>w,\n",
    "    \\end{cases}\n",
    "\\]\n",
    "ensures an $\\mathcal O(nW)$ time solution. We augment the DP table with a boolean \\texttt{take[i][w]} matrix to enable $\\mathcal O(n)$ back‑tracking, thereby recovering the exact subset of items achieving optimal value. Experimental results on benchmark instances demonstrate both correctness and scalability, and the entire codebase, analysis plots, and performance tables are available in accompanying Jupyter notebooks.\\vspace{1ex}\n",
    "\n",
    "\\textbf{Keywords:} 0–1 knapsack, dynamic programming, back‑tracking, Jupyter notebooks, algorithm analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0242da-2d47-4519-8c7e-54b67619c594",
   "metadata": {},
   "source": [
    "For the Genetic Algorithm, we are evolving a population of candidates(binary vectors of length n) over many generations using selection, crossover, mutation and elitism. We start by defining a fitness function that calculates the total value of a candidates and assign a fitness of 0 to any overweight solution, so only valid packings compete. The initial population is created randomly and each individual is a random 0/1 string with length n.The goal is that starting randomly, GA can exploire many regions of the solution space. Next we create the slection function in which we choose a tournamet as a way to select memebers, becouse that type of selection balances selective pressure (favoring better solutions) with genetic diversity (random sampling). We randomlyy pick the tournament_size members and then take the fittest among them. As a next step we create the crossover function with a single-point crossover at random cut. The crossover function main goal is to create a $n$ offsprings which may inherits good subset of items form their parents. We also create the mutation function, whcih flips each bit with a small probability with the main objective to inject a new genetic material to avoid premature convergence and explore unseen packings. And as a last step we run the main loop in which we\n",
    "evaluate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee41eb8-cabc-45ca-a6cf-d659a43123d1",
   "metadata": {},
   "source": [
    "We will solve the 0/1 Knapsack Problem by using a population of binary vectors of length $n$, where each bit indicates whether the corresponding item is included or not. Our GA algorithm will have the following default parameters: \n",
    "- `population_size = 100`  \n",
    "- `num_generations = 200`  \n",
    "- `mutation_rate = 0.01`  \n",
    "- `tournament_size = 3`  \n",
    "- `elitism = True`\n",
    "Our GA algorithm fitness function will the total value of the chosen items if their total weight does not exceed the capacity. Otherwise we assign fitness to 0 to enforce feasibility. We generate an initial population `population_size` individuals by sampling each bit uniformly at random from {0, 1}. The other GA parameters wiil be set as follow:\n",
    "- Selection (Tournament). To choose parents, we perform tournaments of size `tournament_size`, randomly pick that many individuals and select the one with highest fitness. This strikes a balance between selective pressure and genetic diversity.\n",
    "- Crossover. We apply single-point crossover: choose a random cut-point in `[1, n–1]`, and swap the tails of two parents to produce two offspring. This recombines useful building blocks.\n",
    "- Mutation. Each bit of an offspring is flipped with probability `mutation_rate`. Mutation injects new genetic material and helps avoid local optima.\n",
    "- Elitism. If `elitism = True`, the best individual from the current generation is copied unchanged into the next generation, ensuring solution quality never degrades.\n",
    "In the main loop we repeat `num_generations` and evaluate the fitness of all individuals, record the best individual so far and build a new population by either copy the elite or fill the rest by selecting parents, applying crossover, then mutation. At the we truncate the population to `population_size`.\n",
    "The algoritm returns the best value and its corresponding binary vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5482186a-0561-4820-b7a9-f326b4c65be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GA Quality Ratio over Mutation Rate and n\n",
    "pop_sizes = [50, 100, 200, 500]\n",
    "mut_rates = [0.001, 0.01, 0.05, 0.1]\n",
    "heat_results = []\n",
    "# fix one instance\n",
    "w2, v2, C2 = generate_knapsack_instance(300)\n",
    "dp_val2, _, _ = run_dp(w2, v2, C2)\n",
    "for pop in pop_sizes:\n",
    "    for mut in mut_rates:\n",
    "        params = {'population_size': pop, 'num_generations': 200,\n",
    "                  'mutation_rate': mut, 'tournament_size': 3, 'elitism': True}\n",
    "        ga_vals = [run_ga(w2, v2, C2, params)[0] for _ in range(3)]\n",
    "        quality = np.mean(ga_vals) / dp_val2\n",
    "        heat_results.append({'pop': pop, 'mut': mut, 'quality_ratio': quality})\n",
    "df_heat = pd.DataFrame(heat_results)\n",
    "pivot = df_heat.pivot(index='mut', columns='pop', values='quality_ratio').sort_index()\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(pivot.values, aspect='auto', origin='lower')\n",
    "plt.xticks(range(len(pop_sizes)), pop_sizes)\n",
    "plt.yticks(range(len(mut_rates)), mut_rates)\n",
    "plt.xlabel('Population Size')\n",
    "plt.ylabel('Mutation Rate')\n",
    "plt.title('Heatmap: GA Quality Ratio')\n",
    "plt.colorbar(label='Quality Ratio')\n",
    "plt.savefig(\"GA Quality Ration over mutation Rate.png\" )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b31ecb-b59b-480e-bf3a-6a33f1fcf1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "**Function:** `benchmark_with_quality(ns, trials=5)`\n",
    "\n",
    "Run both the exact Dynamic Programming (DP) solver and the Genetic Algorithm (GA) solver on knapsack instances of increasing size, then compare speed and solution quality.\n",
    "#### Procedure\n",
    "1. **Input**\n",
    "   - A list of item counts:  \n",
    "     `ns = [10, 20, 50, 100, …]`\n",
    "   - Number of trials per \\(n\\): `trials` (default 5)\n",
    "2. **For each** \\(n \\in ns\\):\n",
    "   1. **Repeat** `trials` times:\n",
    "      - **Generate** a random knapsack instance with \\(n\\) items.\n",
    "      - **Solve** with DP:\n",
    "        - Record `(dp_value, dp_time)`.\n",
    "      - **Solve** with GA:\n",
    "        - Record `(ga_value, ga_time)`.\n",
    "   2. **Aggregate** across trials:\n",
    "      - \\(\\displaystyle\\overline{dp\\_time}, \\ \\overline{ga\\_time}\\)\n",
    "      - \\(\\displaystyle\\overline{dp\\_value}, \\ \\overline{ga\\_value}\\)\n",
    "      - **Quality ratio:**  \n",
    "        \\[\n",
    "          \\text{quality\\_ratio}\n",
    "          = \\frac{\\overline{ga\\_value}}{\\overline{dp\\_value}}\n",
    "        \\]\n",
    "   3. **Append** one row to `df_quality` with columns:\n",
    "      ```\n",
    "      n | avg_dp_time | avg_ga_time | avg_dp_value | avg_ga_value | quality_ratio \n",
    "       ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
